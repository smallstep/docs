---
title: Smallstep Platform Installation - VM
html_title: Smallstep Platform Installation - VM
description: Learn how to configure your VM infrastructure and install your run anywhere deployment
---


# Smallstep Platform Installation - VM

Smallstep's `run anywhere` deployments require a certain set of infrastructure on which to run. Details about these requirements are listed throughout this guide. VM configurations are highly-customizable, so it will be necessary to work closely with your Smallstep representative to assure that all settings work as intended.

## Setting up AWS Infrastructure

### Dependencies

- [kubectl](https://kubernetes.io/docs/tasks/tools/#kubectl)
- [KOTS](https://kots.io/kots-cli/getting-started/#how-to-install)
- [linkerd](https://linkerd.io/2.10/getting-started/#step-1-install-the-cli)
- [step](https://smallstep.com/docs/step-cli/installation)

### Required Infrastructure to Support `run anywhere`

The `run anywhere` on-premise PKI solution itself runs on a customer-managed Kubernetes cluster. However, the total scope of this project requires the following list of technologies:

1. DNS Solution
    - You will need to set up an Alias record (*.<base_project_domain>) directing traffic to an IP address sitting in front of `run anywhere`.
2. Network Load Balancer (or Reverse Proxy with `run anywhere` exposed as `NodePort`)
    - Will bind to a single IP address on the cluster and connect to a pod which serves as an internal router to all `run anywhere` services
3. PostgreSQL Database
    - Backend storage for `run anywhere`
    - Minimum Specifications
        - Postgres 11+
    - Recommended Specifications
        - Postgres 13+
4. Redis Instance
    - Ephemeral data and Pub/Sub, used by the web app
    - Minimum Specifications
        - Redis 4+
    - Recommended Specifications
        - Redis 5+
5. Kubernetes Cluster
    - Compute resources for the `run anywhere` software stack
    - Minimum Specifications
        - 1 Master Node
        - 2 Worker Nodes
        - 24 GB of Memory
        - 8 GB of RAM
        - 2 CPUs
    - Recommended Specifications
        - 3 Master Nodes
        - 6 Worker Nodes (2 nodes each to provide a failover)
        - 100 GB of Memory
        - 16 GB of RAM
        - 4 CPUs
6. Key Management Solution
    - Can be HSM or KMS - will be used to store the encryption key to your Root Certificate Authority

## Databases

`run anywhere` requires the following 10 databases to be created in your PostgreSQL cluster.

```sql
CREATE DATABASE landlord;
CREATE DATABASE certificates;
CREATE DATABASE web;
CREATE DATABASE depot;
CREATE DATABASE folk;
CREATE DATABASE memoir;
CREATE DATABASE majordomo;
CREATE DATABASE moody;
CREATE DATABASE courier;
```

## Platform

### Install Embedded Cluster on VMs

```bash
curl https://k8s.kurl.sh/smallstep-onboarding | sudo bash -s ha
```

### **Linkerd**

Smallstep services currently use Linkerd for some internal load balancing needs. Install it manually with a long lived certificate. Linkerd comes with a default certificate with a lifetime of 1 year; we donâ€™t want our CA to become useless in 1 year, so this step is necessary. However, we may eventually remove the dependency on Linkerd.

First, create a root CA cert and key:

```bash
step certificate create root.linkerd.cluster.local ca.crt ca.key \
  --profile root-ca --no-password --insecure --not-after=87600h

```

Use the CA to issue an identity certificate for linkerd:

```bash
step certificate create identity.linkerd.cluster.local issuer.crt issuer.key \
  --profile intermediate-ca --not-after 87600h --no-password --insecure \
  --ca ca.crt --ca-key ca.key

```

Install linkerd, providing the files from the previous commands:

```bash
kubectl config use-context <your context>

linkerd install \
  --identity-trust-anchors-file ca.crt \
  --identity-issuer-certificate-file issuer.crt \
  --identity-issuer-key-file issuer.key \
  | kubectl apply -f -
```

Shred the key material:

```bash
shred -uv ca.key issuer.key
```

## Secrets

```bash
 kubectl create secret -n smallstep generic postgresql --from-literal=password=<pg-pass>

 kubectl create secret -n smallstep generic smtp --from-literal=password=<smtp-pass>

# generate random
cat /dev/urandom | head -c 32 | step base64 -u -r | xargs -r echo -n 2> /dev/null
 kubectl create secret -n smallstep generic auth --from-literal=secret=<random-string>

# generate random
cat /dev/urandom | head -c 32 | step base64 -u -r | xargs -r echo -n 2> /dev/null
 kubectl create secret -n smallstep generic majordomo-provisioner-password --from-literal=password=<random-string>

# generate JWK keys
echo -n "{\"keys\": [$(step crypto jwk create /dev/null /dev/stdout --kty RSA --force --no-password --insecure 2> /dev/null &)]}"
 kubectl create secret -n smallstep generic oidc --from-literal=jwks=<json-output>

 kubectl create secret -n smallstep generic scim-server-credentials --from-literal=credentials.json=""
```

### Team and Authority Configuration

Exec into the a `admin-tools` pod to run configuration tooling:

```bash
kubectl exec -it -n smallstep deploy/admin-tools -c admin-tools -- bash
```

**Create a new team**

Make sure the team slug matches the slug used in your smallstep installation.

```bash
create-team
```

**Create a new authority**

Use the convention `ssh.<team-slug>.ca.<base-domain>` for the domain:

```bash
create-authority --ssh

manage-provisioners --ssh --type SSHPOP --name "SSH POP" --authority <authority-id> add

refresh-authority <authority-id>
```

# ðŸŽ‰ðŸ¥‚

**Add OIDC provisioner**

```bash
manage-provisioners --ssh --type OIDC --name "azuread" --listen-address 127.0.0.1:10000 --client-id <client-id> --client-secret <client-secret> --configuration-endpoint <configuraiton-endpoint> --domain <domain>  --authority <authority-id> --tenant-id <azure-tenant-id> add
```

**Note:** After syncing over SCIM, don't forget to update the team SSH directory to point to the new IdP directory.

```bash
kubectl exec -it -n smallstep deploy/admin-tools -c admin-tools -- bash

$ psql folk
> update teams set ssh_directory_id = '<directory-id>' where slug = '<team-slug>';
```